{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Alt-Text Data Analysis - Pandas\n",
        "\n",
        "Comparing content of AI-generated alt text for a set of 1200 images. VLMs used were GPT-4.1, Claude Sonnet 4.5, and Google Gemini 2.5 Pro.\n",
        "\n",
        "This notebook reads in the caption files as csvs, splits according to gender and race demographics, and performs analysis of trends in appearance- and identity-based attributes in the captions. It generates some preliminary tables and heatmaps to visualize the results.\n"
      ],
      "metadata": {
        "id": "3x6QkCV7Zvyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mIvQX5aQfQwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22MO0a8KZj-P"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_chatgpt = pd.read_csv(\"/path/to/file\")\n",
        "df_claude = pd.read_csv(\"/path/to/file\")\n",
        "df_gemini = pd.read_csv(\"/path/to/file\")\n",
        "df_chatgpt"
      ],
      "metadata": {
        "id": "z6cUBpmBSFEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataframe by filename syntax: now have gender and race separated\n",
        "\n",
        "# Function to extract the first two numbers from the filename\n",
        "def extract_numbers(filename):\n",
        "  parts = filename.split('_')\n",
        "  if len(parts) >= 2:\n",
        "    try:\n",
        "      return int(parts[0]), int(parts[1])\n",
        "    except ValueError:\n",
        "      return None, None # Handle cases where parts[0] or parts[1] are not integers\n",
        "  return None, None\n"
      ],
      "metadata": {
        "id": "-8vgdus2dmRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split for chatgpt\n",
        "df_chatgpt[['first_num', 'second_num']] = df_chatgpt['Filename'].apply(lambda x: pd.Series(extract_numbers(x)))\n",
        "\n",
        "# create separate dataframes for each combination of the first and second numbers\n",
        "split_dataframes_chatgpt = {}\n",
        "\n",
        "for first in [1, 2]:\n",
        "  for second in range(1, 7):\n",
        "    df_name = f'df_chatgpt_{first}_{second}'\n",
        "    split_dataframes_chatgpt[df_name] = df_chatgpt[(df_chatgpt['first_num'] == first) & (df_chatgpt['second_num'] == second)].copy()\n",
        "\n",
        "for df_name, dataframe in split_dataframes_chatgpt.items():\n",
        "    print(f\"\\nDataframe for {df_name}:\")\n",
        "    if not dataframe.empty:\n",
        "        display(dataframe.head())\n",
        "    else:\n",
        "        print(\"DataFrame is empty.\")"
      ],
      "metadata": {
        "id": "m8uZ-SlmowCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split for claude\n",
        "df_claude[['first_num', 'second_num']] = df_claude['Filename'].apply(lambda x: pd.Series(extract_numbers(x)))\n",
        "\n",
        "split_dataframes_claude = {}\n",
        "\n",
        "for first in [1, 2]:\n",
        "  for second in range(1, 7):\n",
        "    df_name = f'df_claude_{first}_{second}'\n",
        "    split_dataframes_claude[df_name] = df_claude[(df_claude['first_num'] == first) & (df_claude['second_num'] == second)].copy()\n",
        "\n",
        "for df_name, dataframe in split_dataframes_claude.items():\n",
        "    print(f\"\\nDataframe for {df_name}:\")\n",
        "    if not dataframe.empty:\n",
        "        display(dataframe.head())\n",
        "    else:\n",
        "        print(\"DataFrame is empty.\")"
      ],
      "metadata": {
        "id": "cWzvTcV0o0Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split for gemini\n",
        "df_gemini[['first_num', 'second_num']] = df_gemini['Filename'].apply(lambda x: pd.Series(extract_numbers(x)))\n",
        "\n",
        "split_dataframes_gemini = {}\n",
        "\n",
        "for first in [1, 2]:\n",
        "  for second in range(1, 7):\n",
        "    df_name = f'df_gemini_{first}_{second}'\n",
        "    split_dataframes_gemini[df_name] = df_gemini[(df_gemini['first_num'] == first) & (df_gemini['second_num'] == second)].copy()\n",
        "\n",
        "for df_name, dataframe in split_dataframes_gemini.items():\n",
        "    print(f\"\\nDataframe for {df_name}:\")\n",
        "    if not dataframe.empty:\n",
        "        display(dataframe.head())\n",
        "    else:\n",
        "        print(\"DataFrame is empty.\")"
      ],
      "metadata": {
        "id": "Bw8T6ENho0Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating lists for terms we want to search for\n",
        "\n",
        "skin_strings = [\"light skin\", \"medium skin\", \"dark skin\", \"tan skin\",  \"olive skin\", \"fair skin\", \"brown skin\", \"warm-toned skin\", \"fair-skinned\", \"light-skinned\", \"dark-skinned\", \"tan-skinned\", \"tanned skin\"]\n",
        "hair_strings = [\"brown hair\", \"black hair\", \"red hair\", \"gray hair\", \"white hair\", \"light brown hair\",\n",
        "        \"dark brown hair\", \"dreadlocks\", \"curly hair\", \"natural hair\", \"textured hair\", \"short hair\", \"styled hair\", \"light hair\", \"dark hair\", \"blonde\", \"wavy hair\",\n",
        "              \"curly dark hair\", \"curly black hair\", \"afro\", \"braided hair\"]\n",
        "facial_hair_strings = [\"mustache\", \"beard\", \"sideburns\"]\n",
        "race_strings = [\"African American\", \"Caucasian\", \"Indian\", \"Mexican\", \"Muslim\", \"Hindu\", \"Hispanic\", \"Latino\", \"Latina\", \"Black\", \"white man\", \"white male\", \"white woman\", \"white female\", \"South Asian\", \"white flight attendant\"]\n",
        "gender_strings = [\"woman\", \"man\", \"male\", \"female\", \"girl\", \"boy\", \"he\", \"she\", \"his\", \"her\"]\n"
      ],
      "metadata": {
        "id": "LW6CSWLIfoTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. GPT-4.1 search"
      ],
      "metadata": {
        "id": "I1mO5206vAE8"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "861f3f2b"
      },
      "source": [
        "import re\n",
        "\n",
        "# function to find which skin tone substrings are in a caption as whole words\n",
        "def get_found_substrings(caption, substrings):\n",
        "  found = []\n",
        "  for sub in substrings:\n",
        "    # Use regex to find whole word matches\n",
        "    if re.search(r'\\b' + re.escape(sub) + r'\\b', caption):\n",
        "      found.append(sub)\n",
        "  return found if found else None # Return None if no substrings are found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chatgpt - search for strings\n",
        "\n",
        "# add a new column to each dataframe listing found skin tone substrings\n",
        "for df_name, dataframe in split_dataframes_chatgpt.items():\n",
        "  dataframe['contains_skin'] = dataframe['Caption'].apply(lambda x: get_found_substrings(x, skin_strings))\n",
        "\n",
        "# add new columns for other lists of terms\n",
        "term_lists = {\n",
        "    'contains_hair': hair_strings,\n",
        "    'contains_facial_hair': facial_hair_strings,\n",
        "    'contains_race': race_strings,\n",
        "    'contains_gender': gender_strings\n",
        "}\n",
        "\n",
        "for df_name, dataframe in split_dataframes_chatgpt.items():\n",
        "  for col_name, term_list in term_lists.items():\n",
        "    dataframe[col_name] = dataframe['Caption'].apply(lambda x: get_found_substrings(x, term_list))\n",
        "\n",
        "# display the head of each modified dataframe to verify (optional)\n",
        "for df_name, dataframe in split_dataframes_chatgpt.items():\n",
        "    print(f\"\\nDataframe for {df_name} with found skin tone substrings:\")\n",
        "    display(dataframe.head())"
      ],
      "metadata": {
        "id": "pXR4QWPup7T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b23c98d1"
      },
      "source": [
        "for df_name, dataframe in split_dataframes_chatgpt.items():\n",
        "  print(f\"\\nCounts for {df_name}:\")\n",
        "  for col in dataframe.columns:\n",
        "    if col.startswith('contains_'):\n",
        "      non_none_count = dataframe[col].notna().sum()\n",
        "      none_count = dataframe[col].isna().sum()\n",
        "      print(f\"  {col}: {non_none_count} non-None, {none_count} None\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc007002"
      },
      "source": [
        "# Count the frequency of each unique value within the lists in the 'contains_' columns for ChatGPT\n",
        "chatgpt_term_frequencies = {}\n",
        "for df_name, dataframe in split_dataframes_chatgpt.items():\n",
        "  chatgpt_term_frequencies[df_name] = {}\n",
        "  print(f\"\\nFrequency counts for {df_name}:\")\n",
        "  for col in dataframe.columns:\n",
        "    if col.startswith('contains_') and dataframe[col].notna().any():\n",
        "      all_terms = [item for sublist in dataframe[col].dropna() for item in sublist]\n",
        "      term_counts = pd.Series(all_terms).value_counts()\n",
        "      chatgpt_term_frequencies[df_name][col] = term_counts\n",
        "      print(f\"  {col}:\")\n",
        "      display(term_counts)\n",
        "    elif col.startswith('contains_'):\n",
        "        print(f\"  {col}: No terms found\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Claude Sonnet 4.5 Search (repeat the same process)\n",
        "\n"
      ],
      "metadata": {
        "id": "hlGSruwOH5Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# string counting for claude\n",
        "\n",
        "for df_name, dataframe in split_dataframes_claude.items():\n",
        "  dataframe['contains_skin'] = dataframe['Caption'].apply(lambda x: get_found_substrings(x, skin_strings))\n",
        "\n",
        "term_lists = {\n",
        "    'contains_hair': hair_strings,\n",
        "    'contains_facial_hair': facial_hair_strings,\n",
        "    'contains_race': race_strings,\n",
        "    'contains_gender': gender_strings\n",
        "}\n",
        "\n",
        "for df_name, dataframe in split_dataframes_claude.items():\n",
        "  for col_name, term_list in term_lists.items():\n",
        "    dataframe[col_name] = dataframe['Caption'].apply(lambda x: get_found_substrings(x, term_list))\n",
        "\n",
        "\n",
        "for df_name, dataframe in split_dataframes_claude.items():\n",
        "    print(f\"\\nDataframe for {df_name} with found skin tone substrings:\")\n",
        "    display(dataframe.head())"
      ],
      "metadata": {
        "id": "ojSAq6R_qkkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count non-None values for each 'contains_' column in each dataframe for Claude\n",
        "for df_name, dataframe in split_dataframes_claude.items():\n",
        "  print(f\"\\nCounts for {df_name}:\")\n",
        "  for col in dataframe.columns:\n",
        "    if col.startswith('contains_'):\n",
        "      non_none_count = dataframe[col].notna().sum()\n",
        "      none_count = dataframe[col].isna().sum()\n",
        "      print(f\"  {col}: {non_none_count} non-None, {none_count} None\")"
      ],
      "metadata": {
        "id": "JGrz86A8qv59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the frequency of each unique value within the lists in the 'contains_' columns for Claude\n",
        "claude_term_frequencies = {}\n",
        "for df_name, dataframe in split_dataframes_claude.items():\n",
        "  claude_term_frequencies[df_name] = {}\n",
        "  print(f\"\\nFrequency counts for {df_name}:\")\n",
        "  for col in dataframe.columns:\n",
        "    if col.startswith('contains_') and dataframe[col].notna().any():\n",
        "      all_terms = [item for sublist in dataframe[col].dropna() for item in sublist]\n",
        "      term_counts = pd.Series(all_terms).value_counts()\n",
        "      claude_term_frequencies[df_name][col] = term_counts\n",
        "      print(f\"  {col}:\")\n",
        "      display(term_counts)\n",
        "    elif col.startswith('contains_'):\n",
        "        print(f\"  {col}: No terms found\")"
      ],
      "metadata": {
        "id": "cc10kYwbq8sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Gemini 2.5 Pro Search (repeat again)"
      ],
      "metadata": {
        "id": "fekcsY1ZqhiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# string counts for gemini\n",
        "\n",
        "for df_name, dataframe in split_dataframes_gemini.items():\n",
        "  dataframe['contains_skin'] = dataframe['Caption'].apply(lambda x: get_found_substrings(x, skin_strings))\n",
        "\n",
        "term_lists = {\n",
        "    'contains_hair': hair_strings,\n",
        "    'contains_facial_hair': facial_hair_strings,\n",
        "    'contains_race': race_strings,\n",
        "    'contains_gender': gender_strings\n",
        "}\n",
        "\n",
        "for df_name, dataframe in split_dataframes_gemini.items():\n",
        "  for col_name, term_list in term_lists.items():\n",
        "    dataframe[col_name] = dataframe['Caption'].apply(lambda x: get_found_substrings(x, term_list))\n",
        "\n",
        "for df_name, dataframe in split_dataframes_gemini.items():\n",
        "    print(f\"\\nDataframe for {df_name} with found skin tone substrings:\")\n",
        "    display(dataframe.head())"
      ],
      "metadata": {
        "id": "uWS0B5LlqmTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1L4TACIyQWdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count non-None values for each 'contains_' column in each dataframe for Gemini\n",
        "for df_name, dataframe in split_dataframes_gemini.items():\n",
        "  print(f\"\\nCounts for {df_name}:\")\n",
        "  for col in dataframe.columns:\n",
        "    if col.startswith('contains_'):\n",
        "      non_none_count = dataframe[col].notna().sum()\n",
        "      none_count = dataframe[col].isna().sum()\n",
        "      print(f\"  {col}: {non_none_count} non-None, {none_count} None\")"
      ],
      "metadata": {
        "id": "v2_XBYFJqxhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the frequency of each unique value within the lists in the 'contains_' columns for Gemini\n",
        "gemini_term_frequencies = {}\n",
        "for df_name, dataframe in split_dataframes_gemini.items():\n",
        "  gemini_term_frequencies[df_name] = {}\n",
        "  print(f\"\\nFrequency counts for {df_name}:\")\n",
        "  for col in dataframe.columns:\n",
        "    if col.startswith('contains_') and dataframe[col].notna().any():\n",
        "      all_terms = [item for sublist in dataframe[col].dropna() for item in sublist]\n",
        "      term_counts = pd.Series(all_terms).value_counts()\n",
        "      gemini_term_frequencies[df_name][col] = term_counts\n",
        "      print(f\"  {col}:\")\n",
        "      display(term_counts)\n",
        "    elif col.startswith('contains_'):\n",
        "        print(f\"  {col}: No terms found\")"
      ],
      "metadata": {
        "id": "jTMe0p2vq9i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the complete table!"
      ],
      "metadata": {
        "id": "yuV35vtxRUsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "def build_full_demographic_term_table_safe(chatgpt_dict, claude_dict, gemini_dict, list_cols=None):\n",
        "    if list_cols is None:\n",
        "        list_cols = [\"contains_skin\", \"contains_hair\", \"contains_facial_hair\",\n",
        "                     \"contains_race\", \"contains_gender\"]\n",
        "\n",
        "    models_dict = {\n",
        "        \"gpt\": chatgpt_dict,\n",
        "        \"claude\": claude_dict,\n",
        "        \"gemini\": gemini_dict\n",
        "    }\n",
        "\n",
        "    tone_bins = {\n",
        "        \"light\": [1, 2],\n",
        "        \"medium\": [3, 4],\n",
        "        \"dark\": [5, 6]\n",
        "    }\n",
        "\n",
        "    # Step 1: Collect all unique terms across all models\n",
        "    all_terms_set = set()\n",
        "    for split_dict in models_dict.values():\n",
        "        for idx, df in enumerate(split_dict.values()):\n",
        "            for col in list_cols:\n",
        "                for items in df[col]:\n",
        "                    if items:\n",
        "                        all_terms_set.update(items)\n",
        "\n",
        "    all_terms = sorted(all_terms_set)\n",
        "    output = pd.DataFrame({\"term\": all_terms})\n",
        "\n",
        "    # Step 2: Fill counts for each model + tone bin\n",
        "    for model_name, split_dict in models_dict.items():\n",
        "        for tone_label, skins in tone_bins.items():\n",
        "            c = Counter()\n",
        "            for idx, df in enumerate(split_dict.values()):\n",
        "                gender = (idx // 6) + 1\n",
        "                skin   = (idx % 6) + 1\n",
        "                if skin not in skins:\n",
        "                    continue\n",
        "                for col in list_cols:\n",
        "                    for items in df[col]:\n",
        "                        if items:\n",
        "                            c.update(items)\n",
        "\n",
        "            colname = f\"{model_name}_{tone_label}\"\n",
        "            output[colname] = output['term'].map(c).fillna(0).astype(int)\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "t3djTSD2RUPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_table = build_full_demographic_term_table_safe(\n",
        "    split_dataframes_chatgpt,\n",
        "    split_dataframes_claude,\n",
        "    split_dataframes_gemini,\n",
        "    list_cols=[\"contains_skin\",\"contains_hair\",\"contains_facial_hair\",\"contains_race\",\"contains_gender\"]\n",
        ")\n",
        "\n",
        "final_table\n",
        "# Compute the row-wise total across all columns except 'term'\n",
        "final_table['total_count'] = final_table.drop(columns='term').sum(axis=1)\n",
        "\n",
        "# Keep only rows where total_count >= 10\n",
        "final_table_filtered = final_table[final_table['total_count'] >= 10].copy()\n",
        "\n",
        "# Optional: drop the 'total_count' column if you no longer need it\n",
        "final_table_filtered = final_table_filtered.drop(columns='total_count')\n",
        "\n",
        "final_table_filtered\n",
        "\n"
      ],
      "metadata": {
        "id": "mtrSghNqUaMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_table.to_excel('path/to/file')"
      ],
      "metadata": {
        "id": "liPbHLSPCow2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c4725c4"
      },
      "source": [
        "# Function to display term frequencies per split dataframe for a given model\n",
        "def display_split_frequencies(term_frequencies_dict, model_name):\n",
        "  print(f\"\\nTerm Frequencies per Split Dataframe for {model_name}:\")\n",
        "  for df_name, term_counts_dict in term_frequencies_dict.items():\n",
        "    print(f\"\\n  Dataframe: {df_name}\")\n",
        "    for col, term_counts in term_counts_dict.items():\n",
        "      print(f\"    {col}:\")\n",
        "      display(term_counts.sort_values(ascending=False))\n",
        "\n",
        "# Function to calculate total frequency of each term across all dataframes for a model\n",
        "def calculate_total_frequencies(term_frequencies_dict):\n",
        "  total_frequencies = {}\n",
        "  for df_name, term_counts_dict in term_frequencies_dict.items():\n",
        "    for col, term_counts in term_counts_dict.items():\n",
        "      for term, count in term_counts.items():\n",
        "        if term not in total_frequencies:\n",
        "          total_frequencies[term] = 0\n",
        "        total_frequencies[term] += count\n",
        "  return total_frequencies\n",
        "\n",
        "\n",
        "# Calculate term frequencies per split dataframe for each model\n",
        "# Assuming the cells above already populated split_dataframes_chatgpt, split_dataframes_claude, and split_dataframes_gemini\n",
        "\n",
        "chatgpt_term_frequencies = {}\n",
        "for df_name, dataframe in split_dataframes_chatgpt.items():\n",
        "  chatgpt_term_frequencies[df_name] = {}\n",
        "  for col_name, term_list in term_lists.items():\n",
        "    if col_name in dataframe.columns and dataframe[col_name].notna().any():\n",
        "        all_terms = [item for sublist in dataframe[col_name].dropna() for item in sublist]\n",
        "        term_counts = pd.Series(all_terms).value_counts()\n",
        "        chatgpt_term_frequencies[df_name][col_name] = term_counts\n",
        "\n",
        "claude_term_frequencies = {}\n",
        "for df_name, dataframe in split_dataframes_claude.items():\n",
        "  claude_term_frequencies[df_name] = {}\n",
        "  for col_name, term_list in term_lists.items():\n",
        "    if col_name in dataframe.columns and dataframe[col_name].notna().any():\n",
        "        all_terms = [item for sublist in dataframe[col_name].dropna() for item in sublist]\n",
        "        term_counts = pd.Series(all_terms).value_counts()\n",
        "        claude_term_frequencies[df_name][col_name] = term_counts\n",
        "\n",
        "gemini_term_frequencies = {}\n",
        "for df_name, dataframe in split_dataframes_gemini.items():\n",
        "  gemini_term_frequencies[df_name] = {}\n",
        "  for col_name, term_list in term_lists.items():\n",
        "    if col_name in dataframe.columns and dataframe[col_name].notna().any():\n",
        "        all_terms = [item for sublist in dataframe[col_name].dropna() for item in sublist]\n",
        "        term_counts = pd.Series(all_terms).value_counts()\n",
        "        gemini_term_frequencies[df_name][col_name] = term_counts\n",
        "\n",
        "\n",
        "# Calculate total frequencies for each model\n",
        "total_frequencies_chatgpt = calculate_total_frequencies(chatgpt_term_frequencies)\n",
        "total_frequencies_claude = calculate_total_frequencies(claude_term_frequencies)\n",
        "total_frequencies_gemini = calculate_total_frequencies(gemini_term_frequencies)\n",
        "\n",
        "\n",
        "# Display split frequencies for each model\n",
        "# display_split_frequencies(chatgpt_term_frequencies, \"ChatGPT\")\n",
        "# display_split_frequencies(claude_term_frequencies, \"Claude\")\n",
        "# display_split_frequencies(gemini_term_frequencies, \"Gemini\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e47019b"
      },
      "source": [
        "# Create dataframes from the total frequency dictionaries\n",
        "df_total_chatgpt = pd.DataFrame.from_dict(total_frequencies_chatgpt, orient='index', columns=['ChatGPT Total Count'])\n",
        "df_total_claude = pd.DataFrame.from_dict(total_frequencies_claude, orient='index', columns=['Claude Total Count'])\n",
        "df_total_gemini = pd.DataFrame.from_dict(total_frequencies_gemini, orient='index', columns=['Gemini Total Count'])\n",
        "\n",
        "# Merge the dataframes\n",
        "# Use outer join to include all terms from all models\n",
        "total_comparison_table = df_total_chatgpt.merge(df_total_claude, left_index=True, right_index=True, how='outer')\n",
        "total_comparison_table = total_comparison_table.merge(df_total_gemini, left_index=True, right_index=True, how='outer')\n",
        "\n",
        "# Fill NaN values with 0 (for terms not present in all models)\n",
        "total_comparison_table = total_comparison_table.fillna(0).astype(int)\n",
        "\n",
        "# Sort the table by the total count across all models (optional)\n",
        "total_comparison_table['Total'] = total_comparison_table.sum(axis=1)\n",
        "total_comparison_table = total_comparison_table.sort_values(by='Total', ascending=False).drop('Total', axis=1)\n",
        "\n",
        "# Display the total comparison table\n",
        "print(\"\\nTotal Term Frequencies Across All Split Dataframes:\")\n",
        "display(total_comparison_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing models' term counts"
      ],
      "metadata": {
        "id": "FmOCNqUpsVbb"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "552875a8"
      },
      "source": [
        "def compare_split_frequencies_tables(chatgpt_term_frequencies, claude_term_frequencies, gemini_term_frequencies):\n",
        "    \"\"\"\n",
        "    Compares term frequencies across split dataframes for each model and displays them in tables.\n",
        "    \"\"\"\n",
        "    print(\"\\nComparing Term Frequencies per Split Dataframe Across Models:\")\n",
        "\n",
        "    # define the expected 12 split dataframe names\n",
        "    expected_df_names = []\n",
        "    for first in [1, 2]:\n",
        "        for second in range(1, 7):\n",
        "            expected_df_names.append(f'df_chatgpt_{first}_{second}') # assume consistent naming\n",
        "\n",
        "    for df_name_chatgpt in expected_df_names:\n",
        "        # construct the corresponding dataframe names for Claude and Gemini\n",
        "        df_name_claude = df_name_chatgpt.replace('df_chatgpt_', 'df_claude_')\n",
        "        df_name_gemini = df_name_chatgpt.replace('df_chatgpt_', 'df_gemini_')\n",
        "\n",
        "\n",
        "        print(f\"\\n--- Comparison Table for {df_name_chatgpt} ---\")\n",
        "\n",
        "        # get the term frequencies for the current split from each model, defaulting to empty dict if not present\n",
        "        chatgpt_counts_split = chatgpt_term_frequencies.get(df_name_chatgpt, {})\n",
        "        claude_counts_split = claude_term_frequencies.get(df_name_claude, {})\n",
        "        gemini_counts_split = gemini_term_frequencies.get(df_name_gemini, {})\n",
        "\n",
        "        combined_split_counts = {}\n",
        "\n",
        "        all_terms_in_split = set()\n",
        "        for counts_split in [chatgpt_counts_split, claude_counts_split, gemini_counts_split]:\n",
        "            for col_counts in counts_split.values():\n",
        "                all_terms_in_split.update(col_counts.index)\n",
        "\n",
        "\n",
        "        for term in all_terms_in_split:\n",
        "             combined_split_counts[term] = {'ChatGPT Count': 0, 'Claude Count': 0, 'Gemini Count': 0}\n",
        "             for col in ['contains_skin', 'contains_eyes', 'contains_hair', 'contains_facial_hair', 'contains_race', 'contains_gender']:\n",
        "                if col in chatgpt_counts_split and term in chatgpt_counts_split[col]:\n",
        "                    combined_split_counts[term]['ChatGPT Count'] += chatgpt_counts_split[col][term]\n",
        "                if col in claude_counts_split and term in claude_counts_split[col]:\n",
        "                     combined_split_counts[term]['Claude Count'] += claude_counts_split[col][term]\n",
        "                if col in gemini_counts_split and term in gemini_counts_split[col]:\n",
        "                    combined_split_counts[term]['Gemini Count'] += gemini_counts_split[col][term]\n",
        "\n",
        "\n",
        "        comparison_split_table = pd.DataFrame.from_dict(combined_split_counts, orient='index')\n",
        "\n",
        "        comparison_split_table = comparison_split_table.fillna(0).astype(int)\n",
        "\n",
        "        comparison_split_table['Total'] = comparison_split_table.sum(axis=1)\n",
        "\n",
        "        comparison_split_table = comparison_split_table.sort_values(by='Total', ascending=False)\n",
        "\n",
        "        display(comparison_split_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be2d7d4e"
      },
      "source": [
        "# Call the function to generate and display the comparison tables for each split\n",
        "compare_split_frequencies_tables(chatgpt_term_frequencies, claude_term_frequencies, gemini_term_frequencies)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample heatmap\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "first_six_dfs = [f'df_chatgpt_1_{i}' for i in range(1, 7)]\n",
        "second_six_dfs = [f'df_chatgpt_2_{i}' for i in range(1, 7)]\n",
        "\n",
        "def prepare_heatmap_data(term_frequencies_dict, df_names, term_types):\n",
        "    heatmap_data = {}\n",
        "    for df_name in df_names:\n",
        "        model_name = df_name.split('_')[1]\n",
        "        base_df_name = '_'.join(df_name.split('_')[2:])\n",
        "\n",
        "        if model_name == 'chatgpt':\n",
        "            current_df_name = df_name\n",
        "            counts_split = chatgpt_term_frequencies.get(current_df_name, {})\n",
        "        elif model_name == 'claude':\n",
        "            current_df_name = df_name.replace('df_chatgpt_', 'df_claude_')\n",
        "            counts_split = claude_term_frequencies.get(current_df_name, {})\n",
        "        elif model_name == 'gemini':\n",
        "            current_df_name = df_name.replace('df_chatgpt_', 'df_gemini_')\n",
        "            counts_split = gemini_term_frequencies.get(current_df_name, {})\n",
        "        else:\n",
        "            counts_split = {}\n",
        "\n",
        "\n",
        "        for term_type in term_types:\n",
        "          if term_type in counts_split:\n",
        "            for term, count in counts_split[term_type].items():\n",
        "                if term not in heatmap_data:\n",
        "                    heatmap_data[term] = {}\n",
        "                heatmap_data[term][df_name] = count\n",
        "\n",
        "    heatmap_df = pd.DataFrame.from_dict(heatmap_data, orient='index').fillna(0).astype(int)\n",
        "\n",
        "    ordered_cols = [df for df in df_names if df in heatmap_df.columns]\n",
        "    heatmap_df = heatmap_df[ordered_cols]\n",
        "\n",
        "    return heatmap_df\n",
        "\n",
        "all_term_types = ['contains_skin', 'contains_hair', 'contains_facial_hair', 'contains_race', 'contains_gender']\n",
        "\n",
        "# male data\n",
        "heatmap_first_six_chatgpt = prepare_heatmap_data(chatgpt_term_frequencies, first_six_dfs, all_term_types)\n",
        "heatmap_first_six_claude = prepare_heatmap_data(claude_term_frequencies, [name.replace('chatgpt', 'claude') for name in first_six_dfs], all_term_types)\n",
        "heatmap_first_six_gemini = prepare_heatmap_data(gemini_term_frequencies, [name.replace('chatgpt', 'gemini') for name in first_six_dfs], all_term_types)\n",
        "\n",
        "\n",
        "# female data\n",
        "heatmap_second_six_chatgpt = prepare_heatmap_data(chatgpt_term_frequencies, second_six_dfs, all_term_types)\n",
        "heatmap_second_six_claude = prepare_heatmap_data(claude_term_frequencies, [name.replace('chatgpt', 'claude') for name in second_six_dfs], all_term_types)\n",
        "heatmap_second_six_gemini = prepare_heatmap_data(gemini_term_frequencies, [name.replace('chatgpt', 'gemini') for name in second_six_dfs], all_term_types)\n",
        "\n",
        "\n",
        "def plot_heatmaps(heatmap_dataframes, title):\n",
        "    plt.figure(figsize=(12, len(heatmap_dataframes) * 0.5)) # Adjust figure size based on number of terms\n",
        "    sns.heatmap(heatmap_dataframes, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Fitzpatrick Skin Tone\")\n",
        "    plt.ylabel(\"Terms\")\n",
        "    plt.xticks(ticks=range(len(heatmap_dataframes.columns)), labels=[str(i) for i in range(1, 7)])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# plot heatmaps for all terms. this shows the light, medium, then dark men then women.\n",
        "plot_heatmaps(heatmap_first_six_chatgpt, \"ChatGPT Appearance Term Frequency (Men)\")\n",
        "plot_heatmaps(heatmap_first_six_claude, \"Claude Appearance Term Frequency (Men)\")\n",
        "plot_heatmaps(heatmap_first_six_gemini, \"Gemini Appearance Term Frequency (Men)\")\n",
        "\n",
        "plot_heatmaps(heatmap_second_six_chatgpt, \"ChatGPT Appearance Term Frequency (Women)\")\n",
        "plot_heatmaps(heatmap_second_six_claude, \"Claude Appearance Term Frequency (Women)\")\n",
        "plot_heatmaps(heatmap_second_six_gemini, \"Gemini Appearance Term Frequency (Women)\")"
      ],
      "metadata": {
        "id": "748K0trsTRw6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}